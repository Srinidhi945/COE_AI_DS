{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhPoNDPDe1iOPJwBKNl9lH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**NLP**:Natural Language Processing"],"metadata":{"id":"10HPdMqX8MEn"}},{"cell_type":"markdown","source":["\n","\n","1.   Segmentation\n","2.   tokenization\n","3.   Stemming\n","4.   Lemmatization\n","5.   Part of Speech tagging\n","6.   Named entity recognition\n","\n","Applications\n","* chatbots\n","* speech recognition\n","* auto correction\n","\n"],"metadata":{"id":"0Knsubcu8jiW"}},{"cell_type":"code","source":["!pip install spacy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSYmXUq_-QUm","executionInfo":{"status":"ok","timestamp":1743152520207,"user_tz":-330,"elapsed":3654,"user":{"displayName":"Poreddy Srinidhi","userId":"09070233580182774384"}},"outputId":"ea2b4cba-b0be-46f3-971f-7f2d70c59ff7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n","Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"]}]},{"cell_type":"code","source":["!python -m spacy download en_core_web_sm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WKvyLFM-4wO","executionInfo":{"status":"ok","timestamp":1743152530338,"user_tz":-330,"elapsed":10130,"user":{"displayName":"Poreddy Srinidhi","userId":"09070233580182774384"}},"outputId":"8644dda8-8619-432e-9a8b-8960b3332fae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-sm==3.8.0\n","  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vvlai8Ws_DV-","executionInfo":{"status":"ok","timestamp":1743152585082,"user_tz":-330,"elapsed":3361,"user":{"displayName":"Poreddy Srinidhi","userId":"09070233580182774384"}},"outputId":"7bcfddc5-d709-4575-9a16-e3e5e67d469f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import spacy\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","# Load spaCy's NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Input text\n","text = \"John works at Google in California. He loves programming and playing football.\"\n","\n","# 1. Segmentation (sentence tokenization)\n","sentences = sent_tokenize(text)\n","print(\"Segmentation:\", sentences)\n","\n","# 2. Tokenization (word tokenization)\n","tokens = [word_tokenize(sentence) for sentence in sentences]\n","print(\"Tokenization:\", tokens)\n","\n","# 3. Stemming\n","stemmer = PorterStemmer()\n","stemmed_tokens = [[stemmer.stem(token) for token in sentence] for sentence in tokens]\n","print(\"Stemming:\", stemmed_tokens)\n","\n","# 4. Lemmatization\n","lemmatizer = WordNetLemmatizer()\n","lemmatized_tokens = [[lemmatizer.lemmatize(token) for token in sentence] for sentence in tokens]\n","print(\"Lemmatization:\", lemmatized_tokens)\n","\n","# 5. POS Tagging\n","doc = nlp(text)\n","pos_tags = [(token.text, token.pos_) for token in doc]\n","print(\"POS Tagging:\", pos_tags)\n","\n","# 6. Named Entity Recognition (NER)\n","entities = [(entity.text, entity.label_) for entity in doc.ents]\n","print(\"Named Entities:\", entities)\n","\n","# 7. Parsing (Dependency Parsing)\n","for sent in doc.sents:\n","    for token in sent:\n","        print(f'{token.text:10} -> {token.dep_:10} -> {token.head.text}')\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPNc4dBB_DS1","executionInfo":{"status":"ok","timestamp":1743152717523,"user_tz":-330,"elapsed":11295,"user":{"displayName":"Poreddy Srinidhi","userId":"09070233580182774384"}},"outputId":"8571d069-408e-44c1-ab77-d65ccc482499"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation: ['John works at Google in California.', 'He loves programming and playing football.']\n","Tokenization: [['John', 'works', 'at', 'Google', 'in', 'California', '.'], ['He', 'loves', 'programming', 'and', 'playing', 'football', '.']]\n","Stemming: [['john', 'work', 'at', 'googl', 'in', 'california', '.'], ['he', 'love', 'program', 'and', 'play', 'footbal', '.']]\n","Lemmatization: [['John', 'work', 'at', 'Google', 'in', 'California', '.'], ['He', 'love', 'programming', 'and', 'playing', 'football', '.']]\n","POS Tagging: [('John', 'PROPN'), ('works', 'VERB'), ('at', 'ADP'), ('Google', 'PROPN'), ('in', 'ADP'), ('California', 'PROPN'), ('.', 'PUNCT'), ('He', 'PRON'), ('loves', 'VERB'), ('programming', 'VERB'), ('and', 'CCONJ'), ('playing', 'VERB'), ('football', 'NOUN'), ('.', 'PUNCT')]\n","Named Entities: [('John', 'PERSON'), ('Google', 'ORG'), ('California', 'GPE')]\n","John       -> nsubj      -> works\n","works      -> ROOT       -> works\n","at         -> prep       -> works\n","Google     -> pobj       -> at\n","in         -> prep       -> works\n","California -> pobj       -> in\n",".          -> punct      -> works\n","He         -> nsubj      -> loves\n","loves      -> ROOT       -> loves\n","programming -> xcomp      -> loves\n","and        -> cc         -> programming\n","playing    -> conj       -> programming\n","football   -> dobj       -> playing\n",".          -> punct      -> loves\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"Hello! This is a test sentence.\")\n","for token in doc:\n","    print(token.text, token.pos_)\n","#sample code\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q31GdSLj-7a9","executionInfo":{"status":"ok","timestamp":1743152941685,"user_tz":-330,"elapsed":899,"user":{"displayName":"Poreddy Srinidhi","userId":"09070233580182774384"}},"outputId":"df3b7f83-5f60-4049-a139-d4521c33627b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello INTJ\n","! PUNCT\n","This PRON\n","is AUX\n","a DET\n","test NOUN\n","sentence NOUN\n",". PUNCT\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vKnMQOtZ_hpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ytx4LMtX_hl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dlR2o9zs_hic"},"execution_count":null,"outputs":[]}]}